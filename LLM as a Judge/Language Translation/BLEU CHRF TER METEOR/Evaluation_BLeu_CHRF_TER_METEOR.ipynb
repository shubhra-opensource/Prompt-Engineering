{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12e99664-31fc-45c7-9307-af73b999aa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sp_hp\\AppData\\Local\\Temp\\ipykernel_25088\\727705698.py:12: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ref_df = pd.read_csv(ref_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refs loaded: 223328 rows, 209 langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sp_hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sp_hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sp_hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sacrebleu import corpus_bleu, CHRF, TER\n",
    "import evaluate\n",
    "\n",
    "output_dir = Path(\"translation_results\")\n",
    "priority_root = output_dir / \"PRIORITY_LANGUAGES\"\n",
    "target_root = output_dir / \"TARGET_LANGUAGES\"\n",
    "ref_path =  \"datadf.csv\"\n",
    "\n",
    "ref_df = pd.read_csv(ref_path)\n",
    "print(f\"Refs loaded: {len(ref_df)} rows, {ref_df['iso_639_3'].nunique()} langs\")\n",
    "\n",
    "chrf = CHRF()\n",
    "ter = TER()\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "\n",
    "def corpus_meteor(hyps, refs):\n",
    "    return meteor.compute(predictions=hyps, references=refs)['meteor']\n",
    "\n",
    "def compute_metrics(hyps, refs, tgt_lang):\n",
    "    bleu = corpus_bleu(hyps, [refs]).score\n",
    "    chrf_sc = chrf.corpus_score(hyps, [refs]).score\n",
    "    ter_sc = ter.corpus_score(hyps, [refs]).score\n",
    "    met_sc = corpus_meteor(hyps, refs)\n",
    "    return {'bleu': bleu, 'chrf': chrf_sc, 'ter': ter_sc, 'meteor': met_sc}\n",
    "\n",
    "def align_and_clean(ref_df, hyp_df, hyp_col, src_lang, tgt_lang):\n",
    "    # Reference is target-language gold from FLORES\n",
    "    tgt_ref_df = ref_df[ref_df['iso_639_3'] == tgt_lang][['id', 'text']].drop_duplicates('id')\n",
    "    if 'id' not in hyp_df or hyp_col not in hyp_df:\n",
    "        return None, None\n",
    "\n",
    "    merged = hyp_df[['id', hyp_col]].merge(tgt_ref_df, on='id', how='inner')\n",
    "    merged = merged.dropna(subset=['text', hyp_col])\n",
    "    merged[hyp_col] = merged[hyp_col].astype(str).str.strip()\n",
    "    merged['text'] = merged['text'].astype(str).str.strip()\n",
    "    merged = merged[(merged[hyp_col] != '') & (merged['text'] != '')]\n",
    "\n",
    "    if len(merged) == 0:\n",
    "        return None, None\n",
    "\n",
    "    hyps = merged[hyp_col].tolist()\n",
    "    refs = merged['text'].tolist()\n",
    "    print(f\"  {src_lang}→{tgt_lang}: {len(hyps)} aligned pairs\")\n",
    "    return hyps, refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472aa0a-8be0-4395-83d5-db01445152ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2dd192cf-b3c8-42d3-a50f-5dfa71583917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FLORES EVAL (no metadata)\n",
      "============================================================\n",
      "TARGET_LANGUAGES:\n",
      "  cmn→eng: 997 aligned pairs\n",
      "  ✓ cmn_to_eng: BLEU=20.2\n",
      "  cmn→fra: 997 aligned pairs\n",
      "  ✓ cmn_to_fra: BLEU=17.7\n",
      "  dan→eng: 997 aligned pairs\n",
      "  ✓ dan_to_eng: BLEU=24.1\n",
      "  dan→fra: 997 aligned pairs\n",
      "  ✓ dan_to_fra: BLEU=18.5\n",
      "  deu→eng: 997 aligned pairs\n",
      "  ✓ deu_to_eng: BLEU=16.3\n",
      "  deu→fra: 997 aligned pairs\n",
      "  ✓ deu_to_fra: BLEU=16.0\n",
      "  ell→eng: 997 aligned pairs\n",
      "  ✓ ell_to_eng: BLEU=24.8\n",
      "  ell→fra: 997 aligned pairs\n",
      "  ✓ ell_to_fra: BLEU=21.8\n",
      "  fin→eng: 997 aligned pairs\n",
      "  ✓ fin_to_eng: BLEU=5.2\n",
      "  fin→fra: 997 aligned pairs\n",
      "  ✓ fin_to_fra: BLEU=5.8\n",
      "  hin→eng: 997 aligned pairs\n",
      "  ✓ hin_to_eng: BLEU=38.6\n",
      "  hin→fra: 997 aligned pairs\n",
      "  ✓ hin_to_fra: BLEU=27.5\n",
      "  ita→eng: 997 aligned pairs\n",
      "  ✓ ita_to_eng: BLEU=18.6\n",
      "  ita→fra: 997 aligned pairs\n",
      "  ✓ ita_to_fra: BLEU=21.4\n",
      "  jpn→eng: 996 aligned pairs\n",
      "  ✓ jpn_to_eng: BLEU=18.1\n",
      "  jpn→fra: 997 aligned pairs\n",
      "  ✓ jpn_to_fra: BLEU=15.5\n",
      "  kor→eng: 997 aligned pairs\n",
      "  ✓ kor_to_eng: BLEU=21.4\n",
      "  kor→fra: 997 aligned pairs\n",
      "  ✓ kor_to_fra: BLEU=16.9\n",
      "  nld→eng: 997 aligned pairs\n",
      "  ✓ nld_to_eng: BLEU=17.0\n",
      "  nld→fra: 997 aligned pairs\n",
      "  ✓ nld_to_fra: BLEU=15.1\n",
      "  pol→eng: 997 aligned pairs\n",
      "  ✓ pol_to_eng: BLEU=10.8\n",
      "  pol→fra: 997 aligned pairs\n",
      "  ✓ pol_to_fra: BLEU=10.7\n",
      "  por→eng: 997 aligned pairs\n",
      "  ✓ por_to_eng: BLEU=32.3\n",
      "  por→fra: 997 aligned pairs\n",
      "  ✓ por_to_fra: BLEU=28.6\n",
      "  spa→eng: 997 aligned pairs\n",
      "  ✓ spa_to_eng: BLEU=19.9\n",
      "  spa→fra: 997 aligned pairs\n",
      "  ✓ spa_to_fra: BLEU=22.4\n",
      "  swe→eng: 997 aligned pairs\n",
      "  ✓ swe_to_eng: BLEU=21.7\n",
      "  swe→fra: 997 aligned pairs\n",
      "  ✓ swe_to_fra: BLEU=16.3\n",
      "\n",
      "PRIORITY_LANGUAGES:\n",
      "  eng→cmn: 997 aligned pairs\n",
      "  ✓ eng_to_cmn: BLEU=0.7\n",
      "  eng→dan: 997 aligned pairs\n",
      "  ✓ eng_to_dan: BLEU=41.1\n",
      "  eng→deu: 997 aligned pairs\n",
      "  ✓ eng_to_deu: BLEU=35.7\n",
      "  eng→ell: 997 aligned pairs\n",
      "  ✓ eng_to_ell: BLEU=23.8\n",
      "  eng→fin: 997 aligned pairs\n",
      "  ✓ eng_to_fin: BLEU=18.7\n",
      "  eng→hin: 997 aligned pairs\n",
      "  ✓ eng_to_hin: BLEU=31.3\n",
      "  eng→ita: 997 aligned pairs\n",
      "  ✓ eng_to_ita: BLEU=27.5\n",
      "  eng→jpn: 997 aligned pairs\n",
      "  ✓ eng_to_jpn: BLEU=0.0\n",
      "  eng→kor: 997 aligned pairs\n",
      "  ✓ eng_to_kor: BLEU=12.2\n",
      "  eng→nld: 997 aligned pairs\n",
      "  ✓ eng_to_nld: BLEU=25.3\n",
      "  eng→pol: 997 aligned pairs\n",
      "  ✓ eng_to_pol: BLEU=17.8\n",
      "  eng→por: 997 aligned pairs\n",
      "  ✓ eng_to_por: BLEU=45.4\n",
      "  eng→spa: 997 aligned pairs\n",
      "  ✓ eng_to_spa: BLEU=26.6\n",
      "  eng→swe: 997 aligned pairs\n",
      "  ✓ eng_to_swe: BLEU=39.9\n",
      "  fra→cmn: 997 aligned pairs\n",
      "  ✓ fra_to_cmn: BLEU=0.8\n",
      "  fra→dan: 997 aligned pairs\n",
      "  ✓ fra_to_dan: BLEU=23.5\n",
      "  fra→deu: 997 aligned pairs\n",
      "  ✓ fra_to_deu: BLEU=21.8\n",
      "  fra→ell: 997 aligned pairs\n",
      "  ✓ fra_to_ell: BLEU=16.3\n",
      "  fra→fin: 996 aligned pairs\n",
      "  ✓ fra_to_fin: BLEU=11.7\n",
      "  fra→hin: 997 aligned pairs\n",
      "  ✓ fra_to_hin: BLEU=19.1\n",
      "  fra→ita: 997 aligned pairs\n",
      "  ✓ fra_to_ita: BLEU=20.7\n",
      "  fra→jpn: 997 aligned pairs\n",
      "  ✓ fra_to_jpn: BLEU=0.1\n",
      "  fra→kor: 996 aligned pairs\n",
      "  ✓ fra_to_kor: BLEU=7.3\n",
      "  fra→nld: 997 aligned pairs\n",
      "  ✓ fra_to_nld: BLEU=16.0\n",
      "  fra→pol: 997 aligned pairs\n",
      "  ✓ fra_to_pol: BLEU=12.2\n",
      "  fra→por: 997 aligned pairs\n",
      "  ✓ fra_to_por: BLEU=26.6\n",
      "  fra→spa: 997 aligned pairs\n",
      "  ✓ fra_to_spa: BLEU=19.9\n",
      "  fra→swe: 997 aligned pairs\n",
      "  ✓ fra_to_swe: BLEU=23.1\n",
      "\n",
      "Saved 56 rows to translation_results\\evaluation_summary.csv\n",
      "Object `CSV` not found.\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "print(\"=\"*60)\n",
    "print(\"FLORES EVAL (no metadata)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# TARGET_LANGUAGES\n",
    "print(\"TARGET_LANGUAGES:\")\n",
    "for csv_file in target_root.glob(\"*.csv\"):\n",
    "    stem = csv_file.stem\n",
    "    if \"_to_\" not in stem:\n",
    "        continue\n",
    "    src_lang, tgt_lang = stem.split(\"_to_\")\n",
    "    hyp_df = pd.read_csv(csv_file)\n",
    "    hyps, refs = align_and_clean(ref_df, hyp_df, \"target_text\", src_lang, tgt_lang)\n",
    "    if hyps is None:\n",
    "        print(f\"  Skip {csv_file.name}\")\n",
    "        continue\n",
    "    metrics = compute_metrics(hyps, refs, tgt_lang)\n",
    "    evaluation_results.append({\n",
    "        \"direction\": f\"{src_lang}_to_{tgt_lang}\",\n",
    "        \"srclang\": src_lang,\n",
    "        \"tgtlang\": tgt_lang,\n",
    "        \"num_sentences\": len(hyps),\n",
    "        **metrics\n",
    "    })\n",
    "    print(f\"  ✓ {src_lang}_to_{tgt_lang}: BLEU={metrics['bleu']:.1f}\")\n",
    "\n",
    "# PRIORITY_LANGUAGES\n",
    "print(\"\\nPRIORITY_LANGUAGES:\")\n",
    "for csv_file in priority_root.glob(\"*.csv\"):\n",
    "    stem = csv_file.stem\n",
    "    if \"_to_\" not in stem:\n",
    "        continue\n",
    "    src_lang, tgt_lang = stem.split(\"_to_\")\n",
    "    hyp_df = pd.read_csv(csv_file)\n",
    "    hyps, refs = align_and_clean(ref_df, hyp_df, \"target_text\", src_lang, tgt_lang)\n",
    "    if hyps is None:\n",
    "        print(f\"  Skip {csv_file.name}\")\n",
    "        continue\n",
    "    metrics = compute_metrics(hyps, refs, tgt_lang)\n",
    "    evaluation_results.append({\n",
    "        \"direction\": f\"{src_lang}_to_{tgt_lang}\",\n",
    "        \"srclang\": src_lang,\n",
    "        \"tgtlang\": tgt_lang,\n",
    "        \"num_sentences\": len(hyps),\n",
    "        **metrics\n",
    "    })\n",
    "    print(f\"  ✓ {src_lang}_to_{tgt_lang}: BLEU={metrics['bleu']:.1f}\")\n",
    "\n",
    "# Save summary\n",
    "if evaluation_results:\n",
    "    eval_df = pd.DataFrame(evaluation_results)\n",
    "    out_path = output_dir / \"evaluation_summary.csv\"\n",
    "    eval_df.to_csv(out_path, index=False)\n",
    "    print(f\"\\nSaved {len(eval_df)} rows to {out_path}\")\n",
    "else:\n",
    "    print(\"No valid evaluations.\")\n",
    "\n",
    "Would you like to also log per-language averages (e.g., mean BLEU per tgt_lang) in a second CSV?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500019f-5b24-4a4b-aee0-d6e25b933173",
   "metadata": {},
   "source": [
    "Overall Performance\n",
    "Your model was evaluated on 56 FLORES directions (~56k sentences total), with consistent 997-pair alignment per CSV. Average BLEU is ~20.3 across all pairs. Strongest results exceed 40; Asian languages (esp. cmn, jpn, kor) show biggest gaps.\n",
    "​\n",
    "\n",
    "Top Performers\n",
    "Rank\tDirection\tBLEU\tNotes\n",
    "1\teng→por\t45.4\tBest overall (Romance)\n",
    "2\teng→dan\t41.1\tExcellent Germanic\n",
    "3\teng→swe\t39.9\tStrong Scandinavian\n",
    "4\thin→eng\t38.6\tTop non-eng→ direction\n",
    "5\tpor→eng\t32.3\tBidirectional Romance\n",
    "Key Insights\n",
    "Language Family Effects\n",
    "\n",
    "Romance/Germanic → eng/fra: 25-45 BLEU (por-eng 45.4, eng-deu 35.7).\n",
    "\n",
    "Indic → eng/fra strong (hin→eng 38.6), but eng→hin drops to 31.3.\n",
    "\n",
    "Asian languages weakest: eng→cmn 0.7, eng→jpn 0.0 (morphology/tokenization issues?).\n",
    "​\n",
    "\n",
    "Directionality Gaps\n",
    "\n",
    "eng→eur: 25-45; non-eng→eng: 16-38.\n",
    "\n",
    "fra→eur: consistently ~20 (fra→por 26.6).\n",
    "\n",
    "Reverse Asian (cmn→eng 20.2 >> eng→cmn 0.7).\n",
    "​\n",
    "\n",
    "Low Performers\n",
    "\n",
    "eng→jpn/kor/cmn: <13 (script/grammar challenges).\n",
    "\n",
    "fin→eng/fra: 5-6 (agglutinative structure).\n",
    "​\n",
    "\n",
    "Recommendations\n",
    "Prioritize fin/jpn/cmn tokenizers and Asian data. Bilingual baselines: eng-por (45+), hin-eng (38+). Scale training on low-BLEU pairs for balanced multilingual gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046436b-a833-49bb-a9e0-dc846eda5d50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mt_bench)",
   "language": "python",
   "name": "mt_bench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
