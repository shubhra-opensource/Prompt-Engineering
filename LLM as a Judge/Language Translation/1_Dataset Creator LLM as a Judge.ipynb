{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02cef7e-4e67-41e7-a1c3-c693a8c4e2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sp_hp\\miniconda3\\envs\\mt_benchmark\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ NLLB-200-600M TRANSLATION\n",
      "================================================================================\n",
      "Date: 2026-02-23 08:37:29\n",
      "Device: cuda\n",
      "\n",
      "‚è≥ Loading NLLB model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded successfully!\n",
      "\n",
      "‚è≥ Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sp_hp\\AppData\\Local\\Temp\\ipykernel_11460\\710875769.py:111: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/df.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 997 sentences for English\n",
      "‚úì Loaded 997 sentences for French\n",
      "‚úì Loaded 997 sentences for Japanese\n",
      "‚úì Loaded 997 sentences for Korean\n",
      "‚úì Loaded 997 sentences for Hindi\n",
      "‚úì Loaded 997 sentences for Danish\n",
      "‚úì Loaded 997 sentences for Dutch\n",
      "‚úì Loaded 997 sentences for Finnish\n",
      "‚úì Loaded 997 sentences for German\n",
      "‚úì Loaded 997 sentences for Greek\n",
      "‚úì Loaded 997 sentences for Italian\n",
      "‚úì Loaded 997 sentences for Polish\n",
      "‚úì Loaded 997 sentences for Portuguese\n",
      "‚úì Loaded 997 sentences for Spanish\n",
      "‚úì Loaded 997 sentences for Swedish\n",
      "\n",
      "‚úì Using 997 aligned sentences\n",
      "\n",
      "üìÅ Created folder: results\n",
      "\n",
      "============================================================\n",
      "TRANSLATING FROM ENGLISH\n",
      "============================================================\n",
      "\n",
      "‚û° English ‚Üí Japanese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:02<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÊúàÊõúÊó• „Çπ„Çø„É≥„Éï„Ç©„Éº„ÉâÂ§ßÂ≠¶ÂåªÂ≠¶ÈÉ®„ÅÆÁßëÂ≠¶ËÄÖ„Åü„Å°„ÅØ Á¥∞ËÉû„Çí„Çø„Ç§„ÉóÂà•„Å´ÂàÜÈ°û„Åß„Åç„Çã Êñ∞„Åó„ÅÑË®∫Êñ≠„ÉÑ„Éº„É´„ÇíÁô∫Êòé„Åó„Åü„Åì„Å®„ÇíÁô∫Ë°®„Åó„Åæ„Åó„Åü Ê®ôÊ∫ñÁöÑ„Å™„Ç§„É≥„ÇØ„Ç∏„Çß„ÉÉ„Éà„Éó„É™„É≥„Çø„Éº„Åß Âç∞Âà∑„Åß„Åç„ÇãÂ∞è„Åï„Å™„ÉÅ„ÉÉ„Éó„Åß„Åô\n",
      "\n",
      "‚û° English ‚Üí Mandarin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:11<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Âë®‰∏Ä,ÊñØÂù¶Á¶èÂ§ßÂ≠¶ÂåªÂ≠¶Èô¢ÁöÑÁßëÂ≠¶ÂÆ∂ÂÆ£Â∏ÉÂèëÊòé‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËØäÊñ≠Â∑•ÂÖ∑,ÂèØ‰ª•ÊåâÁ±ªÂûãÂàÜÁ±ªÁªÜËÉû:‰∏Ä‰∏™ÂèØÊâìÂç∞ÁöÑÂ∞èËäØÁâá,\n",
      "\n",
      "‚û° English ‚Üí Korean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:45<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏõîÏöîÏùº, Ïä§ÌÉ†ÌçºÎìú ÎåÄÌïôÍµê ÏùòÍ≥ºÎåÄÌïô Í≥ºÌïôÏûêÎì§ÏùÄ ÏÑ∏Ìè¨Î•º Ïú†ÌòïÎ≥ÑÎ°ú Î∂ÑÎ•òÌï† Ïàò ÏûàÎäî ÏÉàÎ°úÏö¥ ÏßÑÎã® ÎèÑÍµ¨Ïùò Î∞úÎ™ÖÏùÑ Î∞úÌëúÌñàÏäµÎãàÎã§.\n",
      "\n",
      "‚û° English ‚Üí Hindi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:08<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§∏‡•ã‡§Æ‡§µ‡§æ‡§∞ ‡§ï‡•ã ‡§∏‡•ç‡§ü‡•à‡§®‡§´‡•ã‡§∞‡•ç‡§° ‡§Ø‡•Ç‡§®‡§ø‡§µ‡§∞‡•ç‡§∏‡§ø‡§ü‡•Ä ‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§ë‡§´ ‡§Æ‡•á‡§°‡§ø‡§∏‡§ø‡§® ‡§ï‡•á ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï‡•ã‡§Ç ‡§®‡•á ‡§è‡§ï ‡§®‡§è ‡§°‡§æ‡§Ø‡§ó‡•ç‡§®‡•ã‡§∏‡•ç‡§ü‡§ø‡§ï ‡§ü‡•Ç‡§≤ ‡§ï‡•á ‡§Ü‡§µ‡§ø‡§∑‡•ç‡§ï‡§æ‡§∞ ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡•Ä ‡§ú‡•ã ‡§ï‡•ã‡§∂‡§ø‡§ï‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ï‡•ç‡§∞‡§Æ‡§¨‡§¶‡•ç‡§ß ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡§É ‡§è‡§ï ‡§õ‡•ã‡§ü‡§æ ‡§™‡•ç‡§∞‡§ø‡§Ç‡§ü‡•á‡§¨‡§≤ ‡§ö‡§ø‡§™ ‡§ú‡§ø‡§∏‡•á ‡§Æ‡§æ‡§®‡§ï ‡§á‡§Ç‡§ï‡§ú‡•á‡§ü ‡§™‡•ç‡§∞‡§ø‡§Ç‡§ü‡§∞‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§≤‡§ó‡§≠‡§ó ‡§è‡§ï ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§∏‡•á‡§Ç‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "‚û° English ‚Üí Danish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:32<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P√• mandag annoncerede forskere fra Stanford University School of Medicine opfindelsen af et nyt diagnostisk v√¶rkt√∏j, der kan sortere celler efter type: en lille trykbar chip, der kan fremstilles ved hj√¶lp af standard inkjetprinter for muligvis en US-cent hver.\n",
      "\n",
      "‚û° English ‚Üí Dutch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:58<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Op maandag kondigden wetenschappers van de Stanford University School of Medicine de uitvinding aan van een nieuw diagnostisch hulpmiddel dat cellen per type kan sorteren: een kleine afdrukbare chip die kan worden vervaardigd met behulp van standaard inkjetprinters voor mogelijk ongeveer een Amerikaanse cent elk.\n",
      "\n",
      "‚û° English ‚Üí Finnish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maanantaina Stanfordin yliopiston l√§√§ketieteellisen koulun tutkijat ilmoittivat uuden diagnostisen ty√∂kalun keksinn√§st√§, joka voi luokitella soluja tyypin mukaan: pienen tulostettavan chipin, joka voidaan valmistaa tavanomaisilla tinkipullojen tulostareilla.\n",
      "\n",
      "‚û° English ‚Üí German\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:18<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am Montag k√ºndigten Wissenschaftler der Stanford University School of Medicine die Erfindung eines neuen diagnostischen Werkzeugs an, das Zellen nach Typ sortieren kann: Ein winziger druckbarer Chip, der mit standardm√§√üigen Inkjet-Drucker f√ºr m√∂glicherweise etwa einen US-Cent pro St√ºck hergestellt werden kann.\n",
      "\n",
      "‚û° English ‚Üí Greek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [06:34<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Œ§Œ∑ŒΩ ŒîŒµœÖœÑŒ≠œÅŒ±, ŒµœÄŒπœÉœÑŒÆŒºŒøŒΩŒµœÇ Œ±œÄœå œÑŒ∑ŒΩ ŒôŒ±œÑœÅŒπŒ∫ŒÆ Œ£œáŒøŒªŒÆ œÑŒøœÖ Œ†Œ±ŒΩŒµœÄŒπœÉœÑŒ∑ŒºŒØŒøœÖ Œ£œÑŒ¨ŒΩœÜŒøœÅŒΩœÑ Œ±ŒΩŒ±Œ∫ŒøŒØŒΩœâœÉŒ±ŒΩ œÑŒ∑ŒΩ ŒµœÜŒµœçœÅŒµœÉŒ∑ ŒµŒΩœåœÇ ŒΩŒ≠ŒøœÖ ŒµœÅŒ≥Œ±ŒªŒµŒØŒøœÖ Œ¥ŒπŒ¨Œ≥ŒΩœâœÉŒ∑œÇ œÄŒøœÖ ŒºœÄŒøœÅŒµŒØ ŒΩŒ± œÑŒ±ŒæŒπŒΩŒøŒºŒÆœÉŒµŒπ œÑŒ± Œ∫œçœÑœÑŒ±œÅŒ± Œ±ŒΩŒ¨ œÑœçœÄŒø: Œ≠ŒΩŒ± ŒºŒπŒ∫œÅŒøœÉŒ∫ŒøœÄŒπŒ∫œå œÑœÉŒπœÄ œÄŒøœÖ ŒºœÄŒøœÅŒµŒØ ŒΩŒ± Œ∫Œ±œÑŒ±œÉŒ∫ŒµœÖŒ±œÉœÑŒµŒØ œáœÅŒ∑œÉŒπŒºŒøœÄŒøŒπœéŒΩœÑŒ±œÇ œÑœÖœÄŒøœÄŒøŒπŒ∑ŒºŒ≠ŒΩŒµœÇ ŒµŒ∫œÑœÖœÄœâœÑŒπŒ∫Œ≠œÇ œÉœÖœÉŒ∫ŒµœÖŒ≠œÇ ŒºŒµ œÑœÉŒπŒºœÄŒÆ ŒºŒµ ŒºŒµŒªŒ¨ŒΩŒπ Œ≥ŒπŒ± œÄŒπŒ∏Œ±ŒΩœåœÑŒ±œÑŒ± œÄŒµœÅŒØœÄŒøœÖ ŒºŒØŒ± Œ¥ŒµŒ∫Œ¨œÅŒ± Œ∫Œ¨Œ∏Œµ ŒºŒØŒ±.\n",
      "\n",
      "‚û° English ‚Üí Italian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:53<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luned√¨, gli scienziati della Stanford University School of Medicine hanno annunciato l'invenzione di un nuovo strumento diagnostico che pu√≤ ordinare le cellule per tipo: un piccolo chip stampabile che pu√≤ essere prodotto utilizzando stampanti a getto di inchiostro standard per circa un centesimo ciascuno.\n",
      "\n",
      "‚û° English ‚Üí Polish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:46<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W poniedzia≈Çek naukowcy z Stanford University School of Medicine og≈Çosili wynalezienie nowego narzƒôdzia diagnostycznego, kt√≥re mo≈ºe sortowaƒá kom√≥rki wed≈Çug rodzaju: ma≈Çy, drukowalny chip, kt√≥ry mo≈ºe byƒá wytwarzany przy u≈ºyciu standardowych drukarek przenikajƒÖcych atrament za oko≈Ço jeden cent.\n",
      "\n",
      "‚û° English ‚Üí Portuguese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:01<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na segunda-feira, cientistas da Faculdade de Medicina da Universidade de Stanford anunciaram a inven√ß√£o de uma nova ferramenta de diagn√≥stico que pode classificar c√©lulas por tipo: um pequeno chip impress√≠vel que pode ser fabricado usando impressoras de jato de tinta padr√£o, possivelmente por cerca de um centavo cada.\n",
      "\n",
      "‚û° English ‚Üí Spanish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:56<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El lunes, cient√≠ficos de la Facultad de Medicina de la Universidad de Stanford anunciaron la invenci√≥n de una nueva herramienta de diagn√≥stico que puede ordenar las c√©lulas por tipo: un peque√±o chip impresible que se puede fabricar utilizando impresoras de inyecci√≥n de tinta est√°ndar por posiblemente un centavo de d√≥lar cada uno.\n",
      "\n",
      "‚û° English ‚Üí Swedish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:52<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P√• m√•ndagen meddelade forskare vid Medicinska skolan vid Stanford University att de uppfann ett nytt diagnostiskt verktyg som kan sortera celler efter typ: en liten tryckbar chip som kan tillverkas med hj√§lp av vanliga inkjettryckare f√∂r m√∂jligen cirka en amerikansk cent varje.\n",
      "‚úÖ English translations complete\n",
      "\n",
      "============================================================\n",
      "TRANSLATING FROM FRENCH\n",
      "============================================================\n",
      "\n",
      "‚û° French ‚Üí Japanese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:46<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "„Çπ„Çø„É≥„Éï„Ç©„Éº„ÉâÂ§ßÂ≠¶ÂåªÂ≠¶ÈÉ®„ÅÆÁ†îÁ©∂ËÄÖ„Çâ„ÅØ,Á¥∞ËÉû„ÇíÁ®ÆÈ°û„Å´„Çà„Å£„Å¶Âå∫Âà•„Åß„Åç„ÇãÊñ∞„Åó„ÅÑË®∫Êñ≠„ÉÑ„Éº„É´„ÇíÈñãÁô∫„Åô„Çã„Åì„Å®„ÇíÊú¨ÊúàÁô∫Ë°®„Åó„Åæ„Åó„Åü.\n",
      "\n",
      "‚û° French ‚Üí Mandarin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:24<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÊñØÂù¶Á¶èÂ§ßÂ≠¶ÂåªÂ≠¶Èô¢ÁöÑÁßëÂ≠¶ÂÆ∂Âë®‰∏ÄÂÆ£Â∏ÉÂàõÈÄ†‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËØäÊñ≠Â∑•ÂÖ∑,ÂèØ‰ª•Ê†πÊçÆÂÖ∂Á±ªÂûãÂå∫ÂàÜÁªÜËÉû.\n",
      "\n",
      "‚û° French ‚Üí Korean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:09<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïä§ÌÉ†Ìè¨Îìú ÎåÄÌïôÍµê ÏùòÍ≥ºÎåÄÌïô Ïùò Í≥ºÌïôÏûê Îì§ ÏùÄ ÏõîÏöîÏùº Ïóê ÏÉàÎ°úÏö¥ ÏßÑÎã® ÎèÑÍµ¨ Î•º ÎßåÎì§Í≤†Îã§Í≥† Î∞úÌëú ÌïòÏòÄÎã§. Ïù¥ ÎèÑÍµ¨ Îäî ÏÑ∏Ìè¨ Î•º Ï¢ÖÎ•ò Ïóê Îî∞Îùº Íµ¨Î≥Ñ Ìï† Ïàò ÏûàÎäî Í≤É Ïù¥Îã§. Ïù¥ Í∏∞Í≥Ñ Îäî ÌëúÏ§Ä ÏûâÌÅ¨ Ï†úÌä∏ ÌîÑÎ¶∞ÌÑ∞ Î•º ÌÜµÌï¥ ÏÉùÏÇ∞ Îê† Ïàò ÏûàÎäî ÏûëÏùÄ Ïπ© Ïù¥Îã§.\n",
      "\n",
      "‚û° French ‚Üí Hindi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:24<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§∏‡•ç‡§ü‡•à‡§®‡§´‡•ã‡§∞‡•ç‡§° ‡§µ‡§ø‡§∂‡•ç‡§µ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§ï‡•á ‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§ë‡§´ ‡§Æ‡•á‡§°‡§ø‡§∏‡§ø‡§® ‡§ï‡•á ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï‡•ã‡§Ç ‡§®‡•á ‡§∏‡•ã‡§Æ‡§µ‡§æ‡§∞ ‡§ï‡•ã ‡§è‡§ï ‡§®‡§è ‡§®‡•à‡§¶‡§æ‡§®‡§ø‡§ï ‡§â‡§™‡§ï‡§∞‡§£ ‡§ï‡•á ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡•Ä, ‡§ú‡•ã ‡§ï‡•ã‡§∂‡§ø‡§ï‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§â‡§®‡§ï‡•á ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§Ö‡§≤‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§ó‡§æ‡•§ ‡§Ø‡§π ‡§è‡§ï ‡§õ‡•ã‡§ü‡§æ ‡§™‡•ç‡§∞‡§ø‡§Ç‡§ü‡•á‡§¨‡§≤ ‡§ö‡§ø‡§™ ‡§π‡•à, ‡§ú‡§ø‡§∏‡•á ‡§Æ‡§æ‡§®‡§ï ‡§ú‡•á‡§ü ‡§á‡§Ç‡§ï ‡§™‡•ç‡§∞‡§ø‡§Ç‡§ü‡§∞ ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§≤‡§ó‡§≠‡§ó ‡§è‡§ï ‡§∏‡•á‡§Ç‡§ü ‡§°‡•â‡§≤‡§∞ ‡§ï‡•Ä ‡§≤‡§æ‡§ó‡§§ ‡§∏‡•á ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "‚û° French ‚Üí Danish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:03<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forskere fra Stanford University's School of Medicine har p√• mandag annonceret oprettelsen af et nyt diagnostisk v√¶rkt√∏j, der kan skelne celler efter type.\n",
      "\n",
      "‚û° French ‚Üí Dutch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:20<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wetenschappers van de school van geneeskunde van de universiteit van Stanford hebben maandag aangekondigd dat er een nieuw diagnostisch hulpmiddel is ontwikkeld dat de cellen kan onderscheiden op basis van hun type.\n",
      "\n",
      "‚û° French ‚Üí Finnish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:10<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanfordin yliopiston l√§√§ketieteellisen koulun tutkijat ilmoittivat maanantaina uuden diagnostisen ty√∂kalun luomisesta, joka mahdollistaa solujen erottamisen niiden tyypin mukaan.\n",
      "\n",
      "‚û° French ‚Üí German\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:26<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wissenschaftler der Medizinischen Fakult√§t der Universit√§t Stanford haben am Montag die Schaffung eines neuen Diagnosetools angek√ºndigt, mit dem die Zellen je nach Typ unterschieden werden k√∂nnen.\n",
      "\n",
      "‚û° French ‚Üí Greek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [06:40<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ŒüŒπ ŒµœÄŒπœÉœÑŒÆŒºŒøŒΩŒµœÇ œÑŒ∑œÇ ŒôŒ±œÑœÅŒπŒ∫ŒÆœÇ Œ£œáŒøŒªŒÆœÇ œÑŒøœÖ Œ†Œ±ŒΩŒµœÄŒπœÉœÑŒ∑ŒºŒØŒøœÖ Œ£œÑŒ¨ŒΩœÜŒøœÅŒΩœÑ Œ±ŒΩŒ±Œ∫ŒøŒØŒΩœâœÉŒ±ŒΩ œÑŒ∑ŒΩ ŒîŒµœÖœÑŒ≠œÅŒ± œÑŒ∑ŒΩ Œ¥Œ∑ŒºŒπŒøœÖœÅŒ≥ŒØŒ± ŒµŒΩœåœÇ ŒΩŒ≠ŒøœÖ ŒµœÅŒ≥Œ±ŒªŒµŒØŒøœÖ Œ¥ŒπŒ¨Œ≥ŒΩœâœÉŒ∑œÇ, œÑŒø ŒøœÄŒøŒØŒø Œ∏Œ± ŒºœÄŒøœÅŒøœçœÉŒµ ŒΩŒ± Œ¥ŒπŒ±œÜŒøœÅŒøœÄŒøŒπŒÆœÉŒµŒπ œÑŒ± Œ∫œçœÑœÑŒ±œÅŒ± Œ±ŒΩŒ¨ŒªŒøŒ≥Œ± ŒºŒµ œÑŒø ŒµŒØŒ¥ŒøœÇ œÑŒøœÖœÇ.\n",
      "\n",
      "‚û° French ‚Üí Italian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:12<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gli scienziati della Scuola di Medicina dell'Universit√† di Stanford hanno annunciato luned√¨ la creazione di un nuovo strumento diagnostico che permetterebbe di differenziare le cellule in base al loro tipo.\n",
      "\n",
      "‚û° French ‚Üí Polish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [06:07<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naukowcy z Szko≈Çy Medycyny Uniwersytetu Stanforda og≈Çosili w poniedzia≈Çek stworzenie nowego narzƒôdzia diagnostycznego pozwalajƒÖcego odr√≥≈ºniƒá kom√≥rki w zale≈ºno≈õci od ich rodzaju.\n",
      "\n",
      "‚û° French ‚Üí Portuguese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:07<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os cientistas da Faculdade de Medicina da Universidade de Stanford anunciaram nesta segunda-feira a cria√ß√£o de uma nova ferramenta de diagn√≥stico, que permitiria diferenciar as c√©lulas de acordo com o seu tipo.\n",
      "\n",
      "‚û° French ‚Üí Spanish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:39<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cient√≠ficos de la Escuela de Medicina de la Universidad de Stanford anunciaron este lunes la creaci√≥n de una nueva herramienta de diagn√≥stico que permitir√° diferenciar las c√©lulas seg√∫n su tipo.\n",
      "\n",
      "‚û° French ‚Üí Swedish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [05:16<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forskare vid Stanforduniversitetets medicinska skola har p√• m√•ndagen meddelat att de ska skapa ett nytt diagnostiskt verktyg som kan skilja cellerna beroende p√• deras typ.\n",
      "‚úÖ French translations complete\n",
      "\n",
      "============================================================\n",
      "üéâ DONE!\n",
      "Files saved:\n",
      "üìÑ output_judge/english_translations.csv\n",
      "üìÑ output_judge/french_translations.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ==========================================================\n",
    "# MULTI-LANGUAGE TRANSLATION (ENG + FRA ‚Üí All Targets)\n",
    "# Output: ONLY 2 CSV files inside output_judge\n",
    "# ==========================================================\n",
    "\n",
    "# === IMPORT STATEMENTS ===\n",
    "# What this does: Loads all necessary libraries for machine translation\n",
    "# Why we need it: Each library provides specific functionality we need to translate text\n",
    "\n",
    "# torch: PyTorch library - provides tensor operations and GPU support\n",
    "# Why: We need this to run the neural network model on GPU/CPU and handle numerical computations\n",
    "import torch\n",
    "\n",
    "# transformers: Hugging Face library for pre-trained NLP models\n",
    "# AutoTokenizer: Converts text into numbers (tokens) that the model understands\n",
    "# AutoModelForSeq2SeqLM: Loads a sequence-to-sequence language model (translates one language to another)\n",
    "# Why: NLLB model is a translation model that needs tokenization and model loading\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# pandas: Data manipulation library - works with tables/dataframes like Excel\n",
    "# Why: Our dataset is a CSV file, and we need to filter, organize, and save translation results\n",
    "import pandas as pd\n",
    "\n",
    "# time: Built-in Python library for measuring execution time\n",
    "# Why: We want to track how long translations take (performance monitoring)\n",
    "import time\n",
    "\n",
    "# datetime: Built-in Python library for date/time operations\n",
    "# Why: We print timestamps to know when the script ran (for logging/debugging)\n",
    "from datetime import datetime\n",
    "\n",
    "# tqdm: Progress bar library - shows visual progress during long operations\n",
    "# Why: Translation takes time, so we show a progress bar so users know it's working\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pathlib.Path: Modern way to handle file/folder paths (works on Windows/Mac/Linux)\n",
    "# Why: We need to create output folders and save files - Path makes this easier and safer\n",
    "from pathlib import Path\n",
    "\n",
    "# === LANGUAGE CONFIGURATION ===\n",
    "# What this does: Defines which languages we'll translate to and their codes\n",
    "# Why we need it: The translation model needs specific language codes, and we need to organize our target languages\n",
    "# Input: None (configuration data)\n",
    "# Output: Language codes and mappings used throughout the script\n",
    "\n",
    "# TARGET_LANGUAGES: List of ISO 639-3 language codes we want to translate INTO\n",
    "# Why: We translate FROM English/French TO these 14 languages\n",
    "# Format: 3-letter ISO codes (e.g., \"jpn\" = Japanese, \"zho\" = Mandarin Chinese)\n",
    "TARGET_LANGUAGES = [\n",
    "    \"jpn\",  # Japanese\n",
    "    \"zho\",  # Mandarin\n",
    "    \"kor\",  # Korean\n",
    "    \"hin\",  # Hindi\n",
    "    \"dan\",  # Danish\n",
    "    \"nld\",  # Dutch\n",
    "    \"fin\",  # Finnish\n",
    "    \"deu\",  # German\n",
    "    \"ell\",  # Greek\n",
    "    \"ita\",  # Italian\n",
    "    \"pol\",  # Polish\n",
    "    \"por\",  # Portuguese\n",
    "    \"spa\",  # Spanish\n",
    "    \"swe\",  # Swedish\n",
    "]\n",
    "\n",
    "# PRIORITY_LANGUAGES: Source languages we translate FROM\n",
    "# Why: These are our starting points - we have English and French source texts\n",
    "# Business reason: We want to test translation quality from multiple source languages\n",
    "PRIORITY_LANGUAGES = [\"eng\", \"fra\"]\n",
    "\n",
    "# DEFAULT_SCRIPTS: Maps language codes to their writing system codes (ISO 15924)\n",
    "# Why: Some languages have multiple writing systems (e.g., Chinese has Simplified/Hanzi)\n",
    "# Technical reason: NLLB model needs both language code AND script code to translate correctly\n",
    "# Example: \"zho\" (Chinese) + \"Hans\" (Simplified) = \"zho_Hans\" for the model\n",
    "DEFAULT_SCRIPTS = {\n",
    "    \"eng\": \"Latn\",  # Latin script (A-Z alphabet)\n",
    "    \"fra\": \"Latn\",  # Latin script\n",
    "    \"jpn\": \"Jpan\",  # Japanese script (Hiragana, Katakana, Kanji)\n",
    "    \"kor\": \"Hang\",  # Hangul script (Korean alphabet)\n",
    "    \"hin\": \"Deva\",  # Devanagari script (Hindi)\n",
    "    \"dan\": \"Latn\",  # Latin script\n",
    "    \"nld\": \"Latn\",  # Latin script\n",
    "    \"fin\": \"Latn\",  # Latin script\n",
    "    \"deu\": \"Latn\",  # Latin script\n",
    "    \"ell\": \"Grek\",  # Greek script\n",
    "    \"ita\": \"Latn\",  # Latin script\n",
    "    \"pol\": \"Latn\",  # Latin script\n",
    "    \"por\": \"Latn\",  # Latin script\n",
    "    \"spa\": \"Latn\",  # Latin script\n",
    "    \"swe\": \"Latn\",  # Latin script\n",
    "    \"zho\": \"Hans\",  # Simplified Chinese (Han script)\n",
    "}\n",
    "\n",
    "# LANGUAGE_NAMES: Human-readable names for each language code\n",
    "# Why: Makes output messages readable (shows \"Japanese\" instead of \"jpn\")\n",
    "# Business reason: Better user experience when printing progress messages\n",
    "LANGUAGE_NAMES = {\n",
    "    \"eng\": \"English\",\n",
    "    \"fra\": \"French\",\n",
    "    \"jpn\": \"Japanese\",\n",
    "    \"kor\": \"Korean\",\n",
    "    \"hin\": \"Hindi\",\n",
    "    \"dan\": \"Danish\",\n",
    "    \"nld\": \"Dutch\",\n",
    "    \"fin\": \"Finnish\",\n",
    "    \"deu\": \"German\",\n",
    "    \"ell\": \"Greek\",\n",
    "    \"ita\": \"Italian\",\n",
    "    \"pol\": \"Polish\",\n",
    "    \"por\": \"Portuguese\",\n",
    "    \"spa\": \"Spanish\",\n",
    "    \"swe\": \"Swedish\",\n",
    "    \"zho\": \"Mandarin\"\n",
    "}\n",
    "\n",
    "# Function: get_nllb_code\n",
    "# What this does: Combines language code and script code into NLLB model format\n",
    "# Why: NLLB model requires format like \"eng_Latn\" not just \"eng\"\n",
    "# Input: iso_639_3 (3-letter language code), script (4-letter script code)\n",
    "# Output: Combined string like \"eng_Latn\" or \"zho_Hans\"\n",
    "def get_nllb_code(iso_639_3, script):\n",
    "    return f\"{iso_639_3}_{script}\"\n",
    "\n",
    "\n",
    "# === MODEL SETUP ===\n",
    "# What this does: Loads the NLLB translation model and prepares it for use\n",
    "# Why we need it: We need a pre-trained model that can translate between 200+ languages\n",
    "# Input: Model name from Hugging Face\n",
    "# Output: Loaded tokenizer and model ready for translation\n",
    "\n",
    "# Print header with timestamp for logging\n",
    "# Why: Helps track when script ran and what it's doing (useful for debugging)\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ NLLB-200-600M TRANSLATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Device selection: Check if GPU (CUDA) is available, otherwise use CPU\n",
    "# Why: GPUs are 10-100x faster for neural networks, but CPU works if no GPU\n",
    "# Technical reason: Neural networks do lots of parallel math - GPUs excel at this\n",
    "# Business reason: Faster translation = less waiting time\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "print(\"\\n‚è≥ Loading NLLB model...\")\n",
    "\n",
    "# Model name: NLLB-200-Distilled-600M from Facebook/Meta\n",
    "# What: Pre-trained translation model supporting 200+ languages\n",
    "# Why this model: It's specifically designed for many languages, and \"distilled\" means smaller/faster\n",
    "# \"600M\" = 600 million parameters (model size - bigger = better quality but slower)\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "\n",
    "# Tokenizer: Converts text into tokens (numbers) that the model understands\n",
    "# Why: Models work with numbers, not text directly\n",
    "# Input: Text strings like \"Hello world\"\n",
    "# Output: Token IDs like [1234, 5678] that represent the text\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Model: The actual neural network that does translation\n",
    "# from_pretrained: Downloads and loads the pre-trained weights from Hugging Face\n",
    "# torch_dtype: Data type for model weights\n",
    "#   - float16 on GPU: Uses less memory, faster (half precision)\n",
    "#   - float32 on CPU: More accurate, required for CPU compatibility\n",
    "# .to(device): Moves model to GPU or CPU\n",
    "# Why: Model weights are large - float16 saves memory, GPU speeds up computation\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ").to(device)\n",
    "\n",
    "print(\"‚úì Model loaded successfully!\")\n",
    "\n",
    "\n",
    "# === LOAD DATASET ===\n",
    "# What this does: Reads the CSV file and filters sentences by language\n",
    "# Why we need it: We need source texts in English and French to translate\n",
    "# Input: CSV file at \"data/df.csv\" with columns: id, iso_639_3, iso_15924, text\n",
    "# Output: Dictionary of dataframes, one per language, with aligned sentence IDs\n",
    "\n",
    "print(\"\\n‚è≥ Loading dataset...\")\n",
    "\n",
    "# Read CSV file into pandas DataFrame\n",
    "# Input: CSV file with multilingual sentences\n",
    "# Output: DataFrame with columns like id, iso_639_3 (language code), iso_15924 (script), text\n",
    "# Why: CSV is a common data format - easy to share and edit\n",
    "df = pd.read_csv(\"data/df.csv\")\n",
    "\n",
    "# Filter language data: Separate sentences by language\n",
    "# Why: We need to organize sentences by language so we can translate from English/French to others\n",
    "# Input: Full dataframe with all languages mixed together\n",
    "# Output: Dictionary where each key is a language code and value is a filtered dataframe\n",
    "lang_dfs = {}\n",
    "\n",
    "# Loop through all languages we care about (source + target languages)\n",
    "# Why: We need to filter the dataset to only include languages we'll use\n",
    "for lang_code in PRIORITY_LANGUAGES + TARGET_LANGUAGES:\n",
    "    # Get the script code for this language (e.g., \"Latn\" for English)\n",
    "    script = DEFAULT_SCRIPTS[lang_code]\n",
    "    \n",
    "    # Filter dataframe: Keep only rows matching this language AND script\n",
    "    # Why: Some languages have multiple scripts (e.g., Chinese Simplified vs Traditional)\n",
    "    # Technical reason: We need exact matches to ensure correct language/script combination\n",
    "    # Input: Full dataframe\n",
    "    # Output: Filtered dataframe with only this language's sentences\n",
    "    filtered = df[\n",
    "        (df[\"iso_639_3\"] == lang_code) &  # Match language code\n",
    "        (df[\"iso_15924\"] == script)        # Match script code\n",
    "    ].copy()  # .copy() prevents warnings about modifying views\n",
    "    \n",
    "    # Only store if we found sentences for this language\n",
    "    if len(filtered) > 0:\n",
    "        # Sort by ID so sentences are in order (important for alignment)\n",
    "        # Why: We need aligned sentences - same ID = same sentence in different languages\n",
    "        lang_dfs[lang_code] = filtered.sort_values(\"id\")\n",
    "        print(f\"‚úì Loaded {len(filtered)} sentences for {LANGUAGE_NAMES[lang_code]}\")\n",
    "\n",
    "# Ensure aligned IDs: Find sentences that exist in BOTH English and French\n",
    "# Why: We need the same sentences in both source languages for fair comparison\n",
    "# Business reason: We want to compare \"How well does model translate English vs French?\"\n",
    "# Technical reason: We can only compare if we have the same source sentences\n",
    "# Input: Sets of IDs from English and French dataframes\n",
    "# Output: List of common IDs (sentences present in both languages)\n",
    "common_ids = set(lang_dfs[\"eng\"][\"id\"]).intersection(set(lang_dfs[\"fra\"][\"id\"]))\n",
    "# Sort IDs and limit to first 1000 (for faster processing/testing)\n",
    "# Why: Limits dataset size - can remove [:1000] to use all sentences\n",
    "common_ids = sorted(list(common_ids))[:1000]\n",
    "\n",
    "# Filter all language dataframes to only include aligned sentences\n",
    "# Why: We only want sentences that exist in both English and French sources\n",
    "# Input: Full language dataframes\n",
    "# Output: Filtered dataframes with only common IDs, sorted by ID\n",
    "# Data transformation: Each dataframe ‚Üí filtered to common_ids ‚Üí sorted\n",
    "for lang_code in lang_dfs:\n",
    "    lang_dfs[lang_code] = lang_dfs[lang_code][\n",
    "        lang_dfs[lang_code][\"id\"].isin(common_ids)  # Keep only IDs in common_ids\n",
    "    ].sort_values(\"id\")  # Sort by ID for consistency\n",
    "\n",
    "print(f\"\\n‚úì Using {len(common_ids)} aligned sentences\")\n",
    "\n",
    "\n",
    "# === TRANSLATION FUNCTIONS ===\n",
    "# What this does: Contains functions to translate text batches and measure performance\n",
    "# Why we need it: Core translation logic - converts source text to target language\n",
    "# Input: List of source texts, target language code\n",
    "# Output: List of translated texts\n",
    "\n",
    "# Function: batch_translate\n",
    "# What this does: Translates multiple texts at once (batching) for efficiency\n",
    "# Why: Processing multiple texts together is faster than one-by-one (GPU parallelization)\n",
    "# Business reason: Faster processing = lower compute costs and faster results\n",
    "# Input: \n",
    "#   - texts: List of source text strings (e.g., [\"Hello\", \"How are you?\"])\n",
    "#   - tgt_lang: Target language code in NLLB format (e.g., \"jpn_Jpan\" for Japanese)\n",
    "#   - batch_size: How many texts to process at once (default 8)\n",
    "# Output: List of translated text strings (same length as input)\n",
    "def batch_translate(texts, tgt_lang, batch_size=8):\n",
    "    # forced_bos_id: \"Beginning of Sequence\" token ID for target language\n",
    "    # What: Special token that tells model \"start generating in this language\"\n",
    "    # Why: NLLB supports 200+ languages - this token forces correct target language\n",
    "    # Technical reason: Without this, model might generate wrong language\n",
    "    forced_bos_id = tokenizer.convert_tokens_to_ids(tgt_lang)\n",
    "    \n",
    "    # hypotheses: Will store all translated texts\n",
    "    hypotheses = []\n",
    "\n",
    "    # Process texts in batches (e.g., 8 at a time)\n",
    "    # Why: GPUs work best with batches - processes multiple items in parallel\n",
    "    # tqdm: Shows progress bar so user knows how much is done\n",
    "    # Input: Range from 0 to len(texts), stepping by batch_size\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        # Extract batch: Get next batch_size texts (e.g., texts[0:8], then texts[8:16])\n",
    "        # Data transformation: Full list ‚Üí slice of batch_size items\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        # Tokenize: Convert text strings to token IDs (numbers)\n",
    "        # return_tensors=\"pt\": Return PyTorch tensors (not NumPy arrays)\n",
    "        # padding=True: Add padding tokens so all texts in batch have same length\n",
    "        #   Why: Neural networks need fixed-size inputs - padding makes short texts match long ones\n",
    "        # .to(device): Move tensors to GPU or CPU (wherever model is)\n",
    "        # Input: List of text strings\n",
    "        # Output: Tensor of token IDs, shape [batch_size, max_length]\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        ).to(device)\n",
    "\n",
    "        # torch.no_grad(): Disable gradient calculation (we're not training)\n",
    "        # Why: Saves memory and speeds up inference - gradients only needed for training\n",
    "        with torch.no_grad():\n",
    "            # model.generate(): Run the model to generate translations\n",
    "            # **inputs: Unpack tokenized inputs (passes them to model)\n",
    "            # forced_bos_token_id: Force model to start with target language token\n",
    "            # max_length=128: Maximum tokens in output (prevents very long translations)\n",
    "            #   Why: Limits output size - prevents model from generating extremely long text\n",
    "            # num_beams=4: Beam search width (explores 4 best translation paths)\n",
    "            #   What: Beam search tries multiple translation options and picks best\n",
    "            #   Why: Better quality than greedy decoding (picking first option)\n",
    "            #   Trade-off: Higher num_beams = better quality but slower\n",
    "            # Input: Tokenized source texts\n",
    "            # Output: Token IDs of translated texts, shape [batch_size, generated_length]\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                forced_bos_token_id=forced_bos_id,\n",
    "                max_length=128,\n",
    "                num_beams=4\n",
    "            )\n",
    "\n",
    "        # Decode: Convert token IDs back to text strings\n",
    "        # batch_decode: Decode entire batch at once\n",
    "        # skip_special_tokens=True: Remove special tokens like [PAD], [BOS] from output\n",
    "        #   Why: These are model-internal tokens, not part of actual translation\n",
    "        # Input: Tensor of token IDs\n",
    "        # Output: List of translated text strings\n",
    "        # Data transformation: Token IDs [batch_size, length] ‚Üí text strings [batch_size]\n",
    "        hypotheses.extend(\n",
    "            tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        )\n",
    "\n",
    "    return hypotheses\n",
    "\n",
    "\n",
    "# Function: time_translate\n",
    "# What this does: Wrapper that translates texts and measures how long it takes\n",
    "# Why: Performance monitoring - helps understand translation speed\n",
    "# Business reason: Need to know processing time for planning and cost estimation\n",
    "# Input:\n",
    "#   - texts: List of source text strings\n",
    "#   - tgt_lang: Target language code\n",
    "# Output: Tuple of (translated_texts, elapsed_time_in_seconds)\n",
    "def time_translate(texts, tgt_lang):\n",
    "    # Clear GPU cache if using CUDA (GPU)\n",
    "    # Why: Frees up GPU memory from previous operations\n",
    "    # Technical reason: Prevents \"out of memory\" errors during long runs\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Record start time\n",
    "    start = time.time()\n",
    "    \n",
    "    # Perform translation\n",
    "    hyps = batch_translate(texts, tgt_lang)\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    # Return both translations and timing info\n",
    "    return hyps, elapsed\n",
    "\n",
    "\n",
    "# === CREATE OUTPUT FOLDER ===\n",
    "# What this does: Creates a folder to save translation results\n",
    "# Why we need it: We need a place to save the CSV files with translations\n",
    "# Input: Folder path \"results\"\n",
    "# Output: Creates folder if it doesn't exist (no error if it already exists)\n",
    "\n",
    "# Define output directory path\n",
    "# Why: Centralized location for all output files - easier to find results\n",
    "output_dir = Path(\"results\")\n",
    "\n",
    "# Create folder (and parent folders if needed)\n",
    "# parents=True: Create parent directories if they don't exist\n",
    "# exist_ok=True: Don't raise error if folder already exists\n",
    "# Why: Makes script robust - works whether folder exists or not\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"\\nüìÅ Created folder: results\")\n",
    "\n",
    "\n",
    "# === TRANSLATION PHASE ===\n",
    "# What this does: Performs all translations from English and French to all target languages\n",
    "# Why we need it: This is the main work - translating source texts to create dataset\n",
    "# Business reason: We need translations to evaluate model quality (LLM as a Judge)\n",
    "# Input: Source texts in English and French\n",
    "# Output: Lists of translation dictionaries (will be saved to CSV)\n",
    "\n",
    "# Extract source texts: Convert dataframe columns to lists\n",
    "# Why: Translation function expects lists, not dataframes\n",
    "# Data transformation: DataFrame column ‚Üí Python list\n",
    "# Input: DataFrame with \"text\" column\n",
    "# Output: List of text strings\n",
    "sources_eng = lang_dfs[\"eng\"][\"text\"].tolist()\n",
    "sources_fra = lang_dfs[\"fra\"][\"text\"].tolist()\n",
    "\n",
    "# Get NLLB language codes for source languages (not used in this version, but prepared)\n",
    "# Why: These would be used if we needed to specify source language explicitly\n",
    "eng_nllb = get_nllb_code(\"eng\", DEFAULT_SCRIPTS[\"eng\"])\n",
    "fra_nllb = get_nllb_code(\"fra\", DEFAULT_SCRIPTS[\"fra\"])\n",
    "\n",
    "# Initialize lists to store translation results\n",
    "# Why: We'll collect all translations before saving to CSV\n",
    "# Structure: Each item is a dictionary with source, target, original, translated\n",
    "eng_translations = []\n",
    "fra_translations = []\n",
    "\n",
    "\n",
    "# ================= ENGLISH ‚Üí TARGETS =================\n",
    "# What this does: Translates all English sentences to each target language\n",
    "# Why: First source language - we want to compare translation quality from English\n",
    "# Input: English source texts, target language codes\n",
    "# Output: List of translation dictionaries\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRANSLATING FROM ENGLISH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Loop through each target language\n",
    "# Why: We need translations to all 14 target languages\n",
    "for tgt_lang_code in TARGET_LANGUAGES:\n",
    "\n",
    "    # Get script code for target language (e.g., \"Jpan\" for Japanese)\n",
    "    tgt_script = DEFAULT_SCRIPTS[tgt_lang_code]\n",
    "    \n",
    "    # Build NLLB language code (e.g., \"jpn_Jpan\")\n",
    "    # Why: Model needs this specific format to know target language\n",
    "    tgt_nllb = get_nllb_code(tgt_lang_code, tgt_script)\n",
    "\n",
    "    # Print progress message\n",
    "    print(f\"\\n‚û° English ‚Üí {LANGUAGE_NAMES[tgt_lang_code]}\")\n",
    "\n",
    "    # Perform translation: Translate all English texts to this target language\n",
    "    # Input: List of English texts, target language code\n",
    "    # Output: Tuple of (translated_texts, elapsed_time)\n",
    "    hyps, elapsed = time_translate(sources_eng, tgt_nllb)\n",
    "    \n",
    "    # Print first translation as example (for verification)\n",
    "    print(hyps[0])\n",
    "\n",
    "    # Store results: Create dictionary for each translation pair\n",
    "    # Why: We need structured data with source language, target language, original, and translation\n",
    "    # zip(): Pairs up original text with its translation (same index)\n",
    "    # Data transformation: Two lists ‚Üí list of dictionaries\n",
    "    # Input: sources_eng (list), hyps (list of translations)\n",
    "    # Output: List of dictionaries, each with 4 keys\n",
    "    for original, translated in zip(sources_eng, hyps):\n",
    "        eng_translations.append({\n",
    "            \"source_language\": \"eng\",           # Which language we translated from\n",
    "            \"target_language\": tgt_lang_code,   # Which language we translated to\n",
    "            \"original_text\": original,          # Original English text\n",
    "            \"translated_text\": translated       # Translated text in target language\n",
    "        })\n",
    "\n",
    "print(\"‚úÖ English translations complete\")\n",
    "\n",
    "\n",
    "# ================= FRENCH ‚Üí TARGETS =================\n",
    "# What this does: Translates all French sentences to each target language\n",
    "# Why: Second source language - we want to compare translation quality from French\n",
    "# Business reason: Compare \"Does model translate better from English or French?\"\n",
    "# Input: French source texts, target language codes\n",
    "# Output: List of translation dictionaries\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRANSLATING FROM FRENCH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Loop through each target language (same as English loop)\n",
    "# Why: Same target languages, but starting from French instead\n",
    "for tgt_lang_code in TARGET_LANGUAGES:\n",
    "\n",
    "    # Get script code for target language\n",
    "    tgt_script = DEFAULT_SCRIPTS[tgt_lang_code]\n",
    "    \n",
    "    # Build NLLB language code\n",
    "    tgt_nllb = get_nllb_code(tgt_lang_code, tgt_script)\n",
    "\n",
    "    # Print progress message\n",
    "    print(f\"\\n‚û° French ‚Üí {LANGUAGE_NAMES[tgt_lang_code]}\")\n",
    "\n",
    "    # Perform translation: Translate all French texts to this target language\n",
    "    # Input: List of French texts, target language code\n",
    "    # Output: Tuple of (translated_texts, elapsed_time)\n",
    "    hyps, elapsed = time_translate(sources_fra, tgt_nllb)\n",
    "    \n",
    "    # Print first translation as example\n",
    "    print(hyps[0])\n",
    "\n",
    "    # Store results: Create dictionary for each translation pair\n",
    "    # Same structure as English translations, but source_language is \"fra\"\n",
    "    for original, translated in zip(sources_fra, hyps):\n",
    "        fra_translations.append({\n",
    "            \"source_language\": \"fra\",           # Which language we translated from\n",
    "            \"target_language\": tgt_lang_code,   # Which language we translated to\n",
    "            \"original_text\": original,          # Original French text\n",
    "            \"translated_text\": translated       # Translated text in target language\n",
    "        })\n",
    "\n",
    "print(\"‚úÖ French translations complete\")\n",
    "\n",
    "\n",
    "# === SAVE FINAL CSV FILES ===\n",
    "# What this does: Converts translation lists to DataFrames and saves as CSV files\n",
    "# Why we need it: CSV format is easy to share, analyze, and use in other tools\n",
    "# Business reason: These CSV files are the output dataset for LLM evaluation\n",
    "# Input: Lists of translation dictionaries\n",
    "# Output: Two CSV files in the \"results\" folder\n",
    "\n",
    "# Convert lists of dictionaries to pandas DataFrames\n",
    "# Why: DataFrames make it easy to save as CSV and manipulate data\n",
    "# Data transformation: List of dictionaries ‚Üí DataFrame (table format)\n",
    "# Input: eng_translations (list of dicts), fra_translations (list of dicts)\n",
    "# Output: DataFrames with columns: source_language, target_language, original_text, translated_text\n",
    "eng_df = pd.DataFrame(eng_translations)\n",
    "fra_df = pd.DataFrame(fra_translations)\n",
    "\n",
    "# Save DataFrames to CSV files\n",
    "# output_dir / \"filename.csv\": Uses Path object for safe path joining (works on all OS)\n",
    "# index=False: Don't save row numbers as a column (cleaner CSV)\n",
    "# Why: CSV files are universal format - can open in Excel, Python, R, etc.\n",
    "# Expected output location: results/english_translations.csv and results/french_translations.csv\n",
    "eng_df.to_csv(output_dir / \"english_translations.csv\", index=False)\n",
    "fra_df.to_csv(output_dir / \"french_translations.csv\", index=False)\n",
    "\n",
    "# Print completion message with file locations\n",
    "# Why: User needs to know where to find the output files\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ DONE!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"üìÑ output_judge/english_translations.csv\")\n",
    "print(\"üìÑ output_judge/french_translations.csv\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd7e6a-3a06-4aa3-81c4-1a12a6d44de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mt_bench)",
   "language": "python",
   "name": "mt_bench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
